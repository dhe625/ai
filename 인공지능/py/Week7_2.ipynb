{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "text_train의 타입: <class 'list'>\n",
      "text_train의 길이: 25000\n",
      "text_train[6]:\n",
      "b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n",
      "y_train[6]:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "#reviews_train = load_files(\"G:/내 드라이브/3-1/인공지능/py/aclImdb/train\")\n",
    "reviews_train = load_files(\"/Users/leedonghyeok/Downloads/aclImdb/train\")\n",
    "#  text(data)와 label(target)을 포함하고 있는 Bunch object로 반환함\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "print(type(reviews_train))\n",
    "\n",
    "print(\"text_train의 타입: {}\".format(type(text_train)))\n",
    "print(\"text_train의 길이: {}\".format(len(text_train)))\n",
    "print(\"text_train[6]:\\n{}\".format(text_train[6]))\n",
    "print(\"y_train[6]:\\n{}\".format(y_train[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"The Movie was sub-par, but this Television Pilot delivers a great springboard into what has become a Sci-Fi fans Ideal program. The Actors deliver and the special effects (for a television series) are spectacular. Having an intelligent interesting script doesn't hurt either.<br /><br />Stargate SG1 is currently one of my favorite programs.\" \n",
      "\n",
      "<class 'bytes'> \n",
      "\n",
      "b\"The Movie was sub-par, but this Television Pilot delivers a great springboard into what has become a Sci-Fi fans Ideal program. The Actors deliver and the special effects (for a television series) are spectacular. Having an intelligent interesting script doesn't hurt either.  Stargate SG1 is currently one of my favorite programs.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_train[5], \"\\n\")\n",
    "print(type(text_train[5]), \"\\n\")\n",
    "\n",
    "# Python3에서는 text_train 데이터가 문자열이 아닌 문자열 데이터의\n",
    "# binary encoded된 bytes 타입이므로 문자열 앞에 b를 삽입해야 함\n",
    "text_train = [doc.replace(b\"<br />\", b\" \")  for doc in text_train] # <br />을 공백으로 대체\n",
    "print(text_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 샘플 수 (훈련 데이터): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"클래스별 샘플 수 (훈련 데이터): {}\".format(np.bincount(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터의 문서 수: 25000\n",
      "테스트 데이터의 문서 수: 25000\n",
      "클래스별 샘플 수 (학습 데이터): [12500 12500]\n",
      "클래스별 샘플 수 (테스트 데이터): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "#reviews_train = load_files(\"G:/내 드라이브/3-1/인공지능/py/aclImdb/train\")\n",
    "#reviews_test = load_files(\"G:/내 드라이브/3-1/인공지능/py/aclImdb/test\")\n",
    "\n",
    "reviews_train = load_files(\"/Users/leedonghyeok/Downloads/aclImdb/train\")\n",
    "reviews_test = load_files(\"/Users/leedonghyeok/Downloads/aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \")  for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \")  for doc in text_test]\n",
    "\n",
    "print(\"학습 데이터의 문서 수: {}\".format(len(text_train)))\n",
    "print(\"테스트 데이터의 문서 수: {}\".format(len(text_test)))\n",
    "\n",
    "print(\"클래스별 샘플 수 (학습 데이터): {}\".format(np.bincount(y_train)))\n",
    "print(\"클래스별 샘플 수 (테스트 데이터): {}\".format(np.bincount(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘사전의 크기: 13\n",
      "어휘사전의 내용:\n",
      "{'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "# 어휘사전 생성\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bards_words = [\"The fool doth think he is wise,\", \n",
    "              \"but the wise man knows himself to be a fool\"]\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)\n",
    "\n",
    "print(\"어휘사전의 크기: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"어휘사전의 내용:\\n{}\".format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW: <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format> \n",
      "\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 12)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1 \n",
      "\n",
      "BOW의 밀집 표현: \n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "\n",
    "# 대부분 0이 되므로 sparse matrix로 표현\n",
    "print(\"BOW: {}\".format(repr(bag_of_words)), \"\\n\")\n",
    "print(bag_of_words, \"\\n\")\n",
    "\n",
    "# numpy array로 display가 가능함\n",
    "# data size가 큰 경우, 메모리 overflow가 발생할 수 있음\n",
    "# Sparse matrix는 압축된 표현 방식을 사용하므로 메모리 이슈가 생길 가능성이 낮음\n",
    "print(\"BOW의 밀집 표현: \\n{}\".format(bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "reviews_train = load_files(\"/Users/leedonghyeok/Downloads/aclImdb/train\")\n",
    "reviews_test = load_files(\"/Users/leedonghyeok/Downloads/aclImdb/test\")\n",
    "\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \")  for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \")  for doc in text_test]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 개수:74849\n",
      "첫 20개의 특성:\n",
      "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"특성 개수:{}\".format(len(feature_names)))\n",
    "print(\"첫 20개의 특성:\\n{}\".format(feature_names[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20010에서 20030까지의 특성:\n",
      "['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
      "매 2000번째 특성\n",
      "['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bête', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
     ]
    }
   ],
   "source": [
    "print(\"20010에서 20030까지의 특성:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"매 2000번째 특성\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수: 318\n",
      "불용어 일부:\n",
      "['anywhere', 'both', 'of', 'thereafter', 'back', 'wherever', 'four', 'whether', 'call', 'two', 'eg', 'sometime', 'i', 'often', 'once', 'even', 'sometimes', 'take', 'further', 'and']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"불용어 개수: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "\n",
    "# ENGLISH_STOP_WORDS는 frozenset이라는 클래스. 리스트로 변환\n",
    "print(\"불용어 일부:\\n{}\".format(list(ENGLISH_STOP_WORDS)[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
