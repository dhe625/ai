{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate linear regression(다변량 선형회귀)\n",
    "\n",
    "# h𝜃(𝑥) = 𝜃0+𝜃1𝑥1+𝜃2𝑥2+𝜃3𝑥3+𝜃4𝑥4...\n",
    "# linear regression is explainable\n",
    "\n",
    "# Generalization\n",
    "# h𝜃(𝑥) = 𝜃0𝑥0+𝜃1𝑥1+𝜃2𝑥2+𝜃3𝑥3...𝜃n𝑥n (𝑥0 = 1이라고 가정)\n",
    "# = 𝜃ᵀ * 𝑥 (inner(dot) product : 내적)\n",
    "\n",
    "# Gradient Descent is similar with univariate linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (-> Classification)\n",
    "# Logistic(Sigmoid) function을 사용함\n",
    "# Threshold를 기준으로 분류함\n",
    "\n",
    "# [ Problems of linear regression ]\n",
    "\n",
    "# 문제 1 : 새로운 features에 의해 h𝜃(𝑥)가 바뀌어 결과에 영향을 준다\n",
    "# 문제 2 : h(𝑥) < 0, h(𝑥) > 1이 될 수도 있다\n",
    "\n",
    "# Logistic Regression: 0 ≤ h𝜃(x) ≤ 1\n",
    "# g(z) = 1 / 1 + e^-z\n",
    "# h𝜃(𝑥) = g(𝜃ᵀ𝑥)\n",
    "# = 1 / 1 + e^(-𝜃ᵀ𝑥)\n",
    "# 𝜃ᵀ𝑥가 0일 때 h𝜃(𝑥) == 0.5\n",
    "\n",
    "# h(𝑥) is estimated probability\n",
    "# h(𝑥) = 𝑃(𝑦 = 1 , 𝑥;𝜃) : Probability that y = 1, given x, parameterized by 𝜃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary\n",
    "# Logistic regression에서 𝜃값을 미리 알아내어 h𝜃(𝑥)를 단순화한 것\n",
    "\n",
    "# p.11 Linear decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression의 cost function(Squared error function)은 Logistic regression에서 non-convex하다 -> Gradient descent 적용 불가\n",
    "\n",
    "# Cost(h𝜃(𝑥),y) : 예측값과 다르면 다를수록 penalized\n",
    "# = -log(h𝜃(𝑥)) if y = 1\n",
    "# = -log(1 - h𝜃(𝑥)) if y = 0\n",
    "# Convex해진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost(h𝜃(𝑥),y) =  -ylog(h𝜃(𝑥) - (1-y)log(1 - h𝜃(𝑥))\n",
    "# = -(ylog(h𝜃(𝑥)) + (1-y)log(1 - h𝜃(𝑥)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass classification\n",
    "\n",
    "# one-vs-all(one-vs-rest) : Binary classification의 combination으로 생각\n",
    "# - logistic regression으로 학습 (logistic regression classifiers)\n",
    "# - classifiers 중 max h𝜃(𝑥)로 분류"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
