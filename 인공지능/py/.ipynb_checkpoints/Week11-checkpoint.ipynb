{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning\n",
    "# Supervised learning(ex_Classification)\n",
    "# Class labelì´ ì£¼ì–´ì§\n",
    "# Classifiers(model)ë¥¼ í†µí•´ ë¶„ë¥˜ ì§„í–‰\n",
    "\n",
    "# Unsupervised learning(ex_Clustering)\n",
    "# Class labelì´ ì£¼ì–´ì§€ì§€ ì•ŠìŒ\n",
    "# Cluster label : Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised\n",
    "# 1. Classification - Categorical(Discrete or Nominal) labelë¡œ ë¶„ë¥˜\n",
    "# 2. Numeric Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification - a 2 step process\n",
    "\n",
    "# 1. Model construction\n",
    "# train setì€ ëª¨ë¸ì˜ ê¸°ë°˜ì´ ë˜ê³ , ë¯¸ë¦¬ ì •í•´ì§„ class label ì†ì„±ì„ ì´ìš©í•˜ì—¬ test setì˜ labelì„ ì˜ˆì¸¡í•œë‹¤\n",
    "# ë³´í†µ dataë¥¼ ì¼ì • ë¹„ìœ¨(ex_8:2)ë¡œ ë‚˜ëˆ„ì–´ í•œ ìª½ì€ train set, í•œ ìª½ì€ test set\n",
    "# ëª¨ë¸ì€ classification rules, decision tree, mathematical formulae ë“±ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤\n",
    " \n",
    "# 2. Model usage - Estimate accuracy\n",
    "# if test set is used to select models, test set is validation set \n",
    "# test set is independent of training set. Otherwise overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate : ì¸¡ì •í•˜ë‹¤, ì¶”ì¸¡í•˜ë‹¤\n",
    "# tenured : ì¢…ì‹ ì¸\n",
    "# hypothesis : ê°€ì„¤\n",
    "# meningitis : ìˆ˜ë§‰ì—¼\n",
    "# evade : íšŒí”¼í•˜ë‹¤, íƒˆì„¸í•˜ë‹¤\n",
    "# induction : ê·€ë‚© (factì— ì˜í•´ì„œ ìƒˆë¡œìš´ fact ìƒì„±)\n",
    "# deduction : ì—°ì—­ (ruleì— ì˜í•´ì„œ fact ìœ ë„)\n",
    "# prune : ê°€ì§€ë¥¼ ì¹˜ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.12\n",
    "\n",
    "# prior probabilityë¥¼ í†µí•´ êµ¬í•˜ê³ ì í•˜ëŠ” probabilityë¥¼ ê³„ì‚°\n",
    "# evidenceë¥¼ í†µí•´ hypothesisë¥¼ ì„¸ìš°ê³ , ê·¸ hypothesisê°€ ì°¸ì¼ í™•ë¥ (ê·€ë‚©ì  ì§€ì§€ë„) ì¸¡ì •\n",
    "# ì •ë¦¬í•˜ë©´ P(h|e) = P(e|h)P(h)\n",
    "\n",
    "# p.13 ì˜ˆì‹œ ì¤‘ìš”\n",
    "# p.15 ì˜ˆì‹œ ì¤‘ìš”\n",
    "# P(Yes|x)ì™€ P(No|x) ì¤‘ í° ê°’ì„ ì±„íƒ\n",
    "\n",
    "# NaÃ¯ve Bayes Classifierì€ attributesê°€ ì„œë¡œ ë…ë¦½ì´ë¼ê³  ê°€ì •\n",
    "\n",
    "# attibuteë§ˆë‹¤ ë‹¤ë¥´ê²Œ ë‹¤ë¤„ì•¼í•¨\n",
    "# Nominal attibute - countingí•˜ì—¬ í™•ë¥ ë¡œ\n",
    "# continuous value - í™•ë¥ ë¶„í¬ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.23\n",
    "\n",
    "# Issues with NaÃ¯ve Bayes Classifier\n",
    "# 1. ì¸ê³µì§€ëŠ¥ì˜ ê³µì •ì„±ì— ëŒ€í•œ ë¬¸ì œ (ex_P(Yes|Married) = 0 x 3/10 / P(Married))\n",
    "# 2. when NaÃ¯ve Bayes won't be able to classify X as Yes or No (ex_P(X|Yes) = 0, P(X|No) = 0)\n",
    "\n",
    "# p.25ë¡œ í•´ê²°\n",
    "# 1. Laplace\n",
    "# 2. m-estimate\n",
    "# Laplaceì™€ m-estimateê°„ í° ì°¨ì´x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.26 - ê³„ì‚°í•  ì¤„ ì•Œì•„ì•¼í•¨\n",
    "# Laplacian correction (Laplacian estimator)\n",
    "\n",
    "# p.28\n",
    "# documentì—ì„œëŠ” ê°ê°ì˜ termì´ ê°ê°ì˜ attributeë¡œ ì·¨ê¸‰ë¨\n",
    "# ğ›¼ = 1 : Laplace smoothing\n",
    "# ğ›¼ < 1 : Lidstone smoothing\n",
    "\n",
    "# Advantages\n",
    "# 1. Easy to implement\n",
    "# 2. Good results obtained in most of the cases\n",
    "\n",
    "# Disadvantages\n",
    "# 1. attributeê°„ ì˜ì¡´ì„±ì„ ì „í˜€ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤\n",
    "\n",
    "# attributeê°„ ìƒê´€ê´€ê³„ê°€ í´ ê²½ìš° Bayesian Belief Networks (BBN) ì‚¬ìš©í•œë‹¤\n",
    "# https://blog.naver.com/smc503/222113811120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.4\n",
    "# Nodes : test\n",
    "# Branch : outcome of the test\n",
    "# Leaf nodes : class labels or class distribution\n",
    "\n",
    "# Decision tree generation\n",
    "# 1. Tree construction(êµ¬ì¶•) - all the training examples are at the root\n",
    "# 2. Tree pruning(ë‹¤ë“¬ê¸°) - noise or outliersë¥¼ ë°˜ì˜í•˜ëŠ” branches ì œê±°\n",
    "# Constructionê³¼ Pruningì´ ë™ì‹œì— ì¼ì–´ë‚  ìˆ˜ ìˆìŒ\n",
    "\n",
    "# Basic algorithm : greedy algorithm\n",
    "# top-down recursive divide-and-conquer manner\n",
    "# All attributes are \"Categorical\"\n",
    "# Test attributes are selected on the basis of a heuristic(ì§¬ì— ì˜í•œ) or statistical measure (ex_information gain)\n",
    "\n",
    "# Algorithmì˜ stopping criteriaë¥¼ ì•Œì•„ì•¼ í•¨\n",
    "# 1. ëª¨ë“  sampleì´ ê°™ì€ classì— ëª¨ì—¬ìˆì„ ê²½ìš°\n",
    "# 2. ë” ì´ìƒ ë‚˜ëˆŒ attributesê°€ ì—†ì„ ê²½ìš° -> Majority voting ìˆ˜í–‰\n",
    "# 3. ë‚¨ì€ samplesê°€ ì—†ì„ ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Theory\n",
    "# information content ì¶œí˜„ ë¹ˆë„ì— ë”°ë¼ ì ê²Œ ë‚˜ì˜¬ìˆ˜ë¡ ê°€ì¹˜ê°€ ë†’ìŒ\n",
    "# INFORMATION = -log2 (p)\n",
    "\n",
    "# P : average, entropy, expected information...\n",
    "# AVE_INFO (entropy) = - Î£ pk log2 (pk) where Î£ k = 1 to n\n",
    "# AVE_INFOëŠ” nê°œì˜ attributeì˜ Pê°€ ì„œë¡œ ê°™ì„ ê²½ìš° maximized(AVE_INFO = 2)ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.12\n",
    "\n",
    "# How to determine the Best Split\n",
    "# Nodes with â€œpurerâ€ class distribution are preferred - Impurity degreeê°€ ë‚®ì€ ê²ƒì„ ì±„íƒí•œë‹¤\n",
    "\n",
    "# Attribute Selection Measure\n",
    "# 1. Information gain (ì •ë³´ì´ë“) - All attributes are assumed to be \"Categorical\"\n",
    "# 2. Gini index - All attributes are assumed \"continuous-valued\"\n",
    "# 3. Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í‘œì ì¸ Impurity ì§€í‘œ\n",
    "# 1. entropy\n",
    "# 2. Gini index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
