{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning\n",
    "# Supervised learning(ex_Classification)\n",
    "# Class label이 주어짐\n",
    "# Classifiers(model)를 통해 분류 진행\n",
    "\n",
    "# Unsupervised learning(ex_Clustering)\n",
    "# Class label이 주어지지 않음\n",
    "# Cluster label : Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised\n",
    "# 1. Classification - Categorical(Discrete or Nominal) label로 분류\n",
    "# 2. Numeric Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification - a 2 step process\n",
    "\n",
    "# 1. Model construction\n",
    "# train set은 모델의 기반이 되고, 미리 정해진 class label 속성을 이용하여 test set의 label을 예측한다\n",
    "# 보통 data를 일정 비율(ex_8:2)로 나누어 한 쪽은 train set, 한 쪽은 test set\n",
    "# 모델은 classification rules, decision tree, mathematical formulae 등으로 나타낸다\n",
    " \n",
    "# 2. Model usage - Estimate accuracy\n",
    "# if test set is used to select models, test set is validation set \n",
    "# test set is independent of training set. Otherwise overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate : 측정하다, 추측하다\n",
    "# tenured : 종신인\n",
    "# hypothesis : 가설\n",
    "# meningitis : 수막염\n",
    "# evade : 회피하다, 탈세하다\n",
    "# induction : 귀납 (fact에 의해서 새로운 fact 생성)\n",
    "# deduction : 연역 (rule에 의해서 fact 유도)\n",
    "# prune : 가지를 치다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.12\n",
    "\n",
    "# prior probability를 통해 구하고자 하는 probability를 계산\n",
    "# evidence를 통해 hypothesis를 세우고, 그 hypothesis가 참일 확률(귀납적 지지도) 측정\n",
    "# 정리하면 P(h|e) = P(e|h)P(h)\n",
    "\n",
    "# p.13 예시 중요\n",
    "# p.15 예시 중요\n",
    "# P(Yes|x)와 P(No|x) 중 큰 값을 채택\n",
    "\n",
    "# Naïve Bayes Classifier은 attributes가 서로 독립이라고 가정\n",
    "\n",
    "# attibute마다 다르게 다뤄야함\n",
    "# Nominal attibute - counting하여 확률로\n",
    "# continuous value - 확률분포로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.23\n",
    "\n",
    "# Issues with Naïve Bayes Classifier\n",
    "# 1. 인공지능의 공정성에 대한 문제 (ex_P(Yes|Married) = 0 x 3/10 / P(Married))\n",
    "# 2. when Naïve Bayes won't be able to classify X as Yes or No (ex_P(X|Yes) = 0, P(X|No) = 0)\n",
    "\n",
    "# p.25로 해결\n",
    "# 1. Laplace\n",
    "# 2. m-estimate\n",
    "# Laplace와 m-estimate간 큰 차이x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.26 - 계산할 줄 알아야함\n",
    "# Laplacian correction (Laplacian estimator)\n",
    "\n",
    "# p.28\n",
    "# document에서는 각각의 term이 각각의 attribute로 취급됨\n",
    "# 𝛼 = 1 : Laplace smoothing\n",
    "# 𝛼 < 1 : Lidstone smoothing\n",
    "\n",
    "# Advantages\n",
    "# 1. Easy to implement\n",
    "# 2. Good results obtained in most of the cases\n",
    "\n",
    "# Disadvantages\n",
    "# 1. attribute간 의존성을 전혀 고려하지 않는다\n",
    "\n",
    "# attribute간 상관관계가 클 경우 Bayesian Belief Networks (BBN) 사용한다\n",
    "# https://blog.naver.com/smc503/222113811120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.4\n",
    "# Nodes : test\n",
    "# Branch : outcome of the test\n",
    "# Leaf nodes : class labels or class distribution\n",
    "\n",
    "# Decision tree generation\n",
    "# 1. Tree construction(구축) - all the training examples are at the root\n",
    "# 2. Tree pruning(다듬기) - noise or outliers를 반영하는 branches 제거\n",
    "# Construction과 Pruning이 동시에 일어날 수 있음\n",
    "\n",
    "# Basic algorithm : greedy algorithm\n",
    "# top-down recursive divide-and-conquer manner\n",
    "# All attributes are \"Categorical\"\n",
    "# Test attributes are selected on the basis of a heuristic(짬에 의한) or statistical measure (ex_information gain)\n",
    "\n",
    "# Algorithm의 stopping criteria를 알아야 함\n",
    "# 1. 모든 sample이 같은 class에 모여있을 경우\n",
    "# 2. 더 이상 나눌 attributes가 없을 경우 -> Majority voting 수행\n",
    "# 3. 남은 samples가 없을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Theory\n",
    "# information content 출현 빈도에 따라 적게 나올수록 가치가 높음\n",
    "# INFORMATION = -log2 (p)\n",
    "\n",
    "# P : average, entropy, expected information...\n",
    "# AVE_INFO (entropy) = - Σ pk log2 (pk) where Σ k = 1 to n\n",
    "# AVE_INFO는 n개의 attribute의 P가 서로 같을 경우 maximized(AVE_INFO = 2)됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p.12\n",
    "\n",
    "# How to determine the Best Split\n",
    "# Nodes with “purer” class distribution are preferred - Impurity degree가 낮은 것을 채택한다\n",
    "\n",
    "# Attribute Selection Measure\n",
    "# 1. Information gain (정보이득) - All attributes are assumed to be \"Categorical\"\n",
    "# 2. Gini index - All attributes are assumed \"continuous-valued\"\n",
    "# 3. Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대표적인 Impurity 지표\n",
    "# 1. entropy\n",
    "# 2. Gini index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
